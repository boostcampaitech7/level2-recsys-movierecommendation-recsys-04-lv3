{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, input_dims, embedding_dim, mlp_dims, drop_rate=0.1):\n",
    "        super(DeepFM, self).__init__()\n",
    "        total_input_dim = int(sum(input_dims))\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros((1,)))\n",
    "        self.fc = nn.Embedding(total_input_dim, 1)\n",
    "        \n",
    "        self.embedding = nn.Embedding(total_input_dim, embedding_dim) \n",
    "        self.embedding_dim = len(input_dims) * embedding_dim\n",
    "\n",
    "        mlp_layers = []\n",
    "        for i, dim in enumerate(mlp_dims):\n",
    "            if i==0:\n",
    "                mlp_layers.append(nn.Linear(self.embedding_dim, dim))\n",
    "            else:\n",
    "                mlp_layers.append(nn.Linear(mlp_dims[i-1], dim))\n",
    "            mlp_layers.append(nn.ReLU(True))\n",
    "            mlp_layers.append(nn.Dropout(drop_rate))\n",
    "        mlp_layers.append(nn.Linear(mlp_dims[-1], 1))\n",
    "        self.mlp_layers = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def fm(self, x):\n",
    "        embed_x = self.embedding(x)\n",
    "        fm_y = self.bias + torch.sum(self.fc(x), dim=1)\n",
    "        square_of_sum = torch.sum(embed_x, dim=1) ** 2         \n",
    "        sum_of_square = torch.sum(embed_x ** 2, dim=1) \n",
    "        fm_y += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n",
    "        return fm_y\n",
    "    \n",
    "    def mlp(self, x):\n",
    "        embed_x = self.embedding(x) \n",
    "        inputs = embed_x.view(-1, self.embedding_dim)\n",
    "        mlp_y = self.mlp_layers(inputs)\n",
    "        return mlp_y\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed_x = self.embedding(x)\n",
    "        fm_y = self.fm(x).squeeze(1)\n",
    "        mlp_y = self.mlp(x).squeeze(1)\n",
    "        y = torch.sigmoid(fm_y + mlp_y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "def FMpreprecessing(data_dir):\n",
    "    train_ratings = pd.read_csv(f\"{data_dir}/train/train_ratings.csv\", sep=',')\n",
    "\n",
    "    train_ratings['rating'] = 1.0 # implicit feedback\n",
    "    train_ratings.drop(['time'],axis=1,inplace=True)\n",
    "\n",
    "    users = set(train_ratings.loc[:, 'user'])\n",
    "    items = set(train_ratings.loc[:, 'item'])\n",
    "\n",
    "    num_negative = 50\n",
    "    user_group_dfs = list(train_ratings.groupby('user')['item'])\n",
    "    first_row = True\n",
    "    user_neg_dfs = pd.DataFrame()\n",
    "\n",
    "    for u, u_items in tqdm(user_group_dfs):\n",
    "        u_items = set(u_items)\n",
    "        i_user_neg_item = np.random.choice(list(items - u_items), num_negative, replace=False)\n",
    "        \n",
    "        i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'rating': [0]*num_negative})\n",
    "        if first_row == True:\n",
    "            user_neg_dfs = i_user_neg_df\n",
    "            first_row = False\n",
    "        else:\n",
    "            user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n",
    "\n",
    "    train_ratings = pd.concat([train_ratings, user_neg_dfs], axis = 0, sort=False)\n",
    "\n",
    "    users = list(set(train_ratings.loc[:,'user']))\n",
    "    users.sort()\n",
    "    items =  list(set((train_ratings.loc[:, 'item'])))\n",
    "    items.sort()\n",
    "\n",
    "    if len(users)-1 != max(users):\n",
    "        users_dict = {users[i]: i for i in range(len(users))}\n",
    "        train_ratings['user']  = train_ratings['user'].map(lambda x : users_dict[x])\n",
    "        users = list(set(train_ratings.loc[:,'user']))\n",
    "        \n",
    "    if len(items)-1 != max(items):\n",
    "        items_dict = {items[i]: i for i in range(len(items))}\n",
    "        train_ratings['item']  = train_ratings['item'].map(lambda x : items_dict[x])\n",
    "        items =  list(set((train_ratings.loc[:, 'item'])))\n",
    "\n",
    "    data = train_ratings.sort_values(by=['user'])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    n_data = len(data)\n",
    "    n_user = len(users)\n",
    "    n_item = len(items)\n",
    "\n",
    "    user_col = torch.tensor(data.loc[:,'user'])\n",
    "    item_col = torch.tensor(data.loc[:,'item'])\n",
    "\n",
    "    offsets = [0, n_user, n_user+n_item]\n",
    "    for col, offset in zip([user_col, item_col], offsets):\n",
    "        col += offset\n",
    "\n",
    "    X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1)], dim=1)\n",
    "    y = torch.tensor(list(data.loc[:,'rating']))\n",
    "\n",
    "    return X, y, n_data, n_user, n_item\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, input_tensor, target_tensor):\n",
    "        self.input_tensor = input_tensor.long()\n",
    "        self.target_tensor = target_tensor.long()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_tensor[index], self.target_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_tensor.size(0)\n",
    "\n",
    "\n",
    "def FMdataloader(data_dir):\n",
    "    print(\"Make Dataloader\")\n",
    "    X, y, n_data, n_user, n_item = FMpreprecessing(data_dir)\n",
    "\n",
    "    dataset = FMDataset(X, y)\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    train_size = int(train_ratio * n_data)\n",
    "    test_size = n_data - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, (n_user, n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "\n",
    "class MlflowManager:\n",
    "    '''\n",
    "    MLflow 관리를 위한 클래스\n",
    "    \n",
    "    MLflow UI 실행 방법:\n",
    "    mlflow ui -h 0.0.0.0 -p 30627\n",
    "\n",
    "    Attributes:\n",
    "        user_name: MLflow 사용자 이름 (str)\n",
    "        tracking_uri: MLflow 추적 URI (str)\n",
    "        experiment_name: MLflow 실험 이름 (str)\n",
    "\n",
    "    Methods:\n",
    "        init: MLflow 초기 설정\n",
    "        start_run: MLflow 실행 시작\n",
    "        log_params: 파라미터 로깅\n",
    "        log_metric: 메트릭 로깅\n",
    "        log_artifact: 아티팩트 로깅\n",
    "        log_model: 모델 로깅\n",
    "        end_run: MLflow 실행 종료\n",
    "        autolog: MLflow 자동 로깅 설정\n",
    "        get_tracking_uri: 현재 설정된 tracking URI 반환\n",
    "        get_artifact_uri: 현재 아티팩트 URI 반환\n",
    "    '''\n",
    "    def __init__(self, user_name=\"root\", tracking_uri=\"http://10.28.224.212\", port=30627, experiment_name=\"tmp\"):\n",
    "        \"\"\"\n",
    "        MlflowManager 클래스 초기화\n",
    "\n",
    "        Args:\n",
    "            user_name (str): MLflow 사용자 이름\n",
    "            tracking_uri (str): MLflow 추적 서버 URI\n",
    "            port (int): MLflow 추적 서버 포트\n",
    "            experiment_name (str): MLflow 실험 이름\n",
    "        \"\"\"\n",
    "        self.user_name = user_name\n",
    "        os.environ[\"LOGNAME\"] = self.user_name\n",
    "        self.tracking_uri = f\"{tracking_uri}:{port}\"\n",
    "        self.experiment_name = experiment_name\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"MLflow 초기 설정\"\"\"\n",
    "        mlflow.set_tracking_uri(self.tracking_uri)\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def start_run(self, run_name=None):\n",
    "        \"\"\"\n",
    "        MLflow 실행 시작\n",
    "\n",
    "        Args:\n",
    "            run_name (str, optional): 실행 이름\n",
    "\n",
    "        Returns:\n",
    "            mlflow.ActiveRun: 활성화된 MLflow 실행 객체\n",
    "        \"\"\"\n",
    "        return mlflow.start_run(run_name=run_name)\n",
    "\n",
    "    def log_params(self, params):\n",
    "        \"\"\"\n",
    "        파라미터 로깅\n",
    "\n",
    "        Args:\n",
    "            params (dict): 로깅할 파라미터 딕셔너리\n",
    "        \"\"\"\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    def log_metric(self, key, value, step):\n",
    "        \"\"\"\n",
    "        메트릭 로깅\n",
    "\n",
    "        Args:\n",
    "            key (str): 메트릭 이름\n",
    "            value (float): 메트릭 값\n",
    "            step (int): 현재 스텝\n",
    "        \"\"\"\n",
    "        mlflow.log_metric(key, value, step)\n",
    "\n",
    "    def log_artifact(self, local_path):\n",
    "        \"\"\"\n",
    "        아티팩트 로깅\n",
    "\n",
    "        Args:\n",
    "            local_path (str): 로깅할 아티팩트의 로컬 경로\n",
    "        \"\"\"\n",
    "        mlflow.log_artifact(local_path)\n",
    "\n",
    "    def log_model(self, model, artifact_path, type='torch'):\n",
    "        \"\"\"\n",
    "        모델 로깅\n",
    "\n",
    "        Args:\n",
    "            model: 로깅할 모델 객체\n",
    "            artifact_path (str): 아티팩트 저장 경로\n",
    "            type (str): 모델 타입 ('torch' 또는 'lgb')\n",
    "\n",
    "        Raises:\n",
    "            Exception: 지원되지 않는 모델 타입일 경우 발생\n",
    "        \"\"\"\n",
    "        if type == 'torch':\n",
    "            mlflow.pytorch.log_model(model, artifact_path)\n",
    "        elif type == 'lgb':\n",
    "            mlflow.lightgbm.log_model(model, artifact_path)\n",
    "        else:\n",
    "            raise Exception(f\"Check type: {type}\")\n",
    "        return None\n",
    "\n",
    "    def end_run(self):\n",
    "        \"\"\"MLflow 실행 종료\"\"\"\n",
    "        mlflow.end_run()\n",
    "\n",
    "    def get_tracking_uri(self):\n",
    "        \"\"\"\n",
    "        현재 설정된 tracking URI 반환\n",
    "\n",
    "        Returns:\n",
    "            str: 현재 설정된 tracking URI\n",
    "        \"\"\"\n",
    "        return mlflow.get_tracking_uri()\n",
    "\n",
    "    def get_artifact_uri(self):\n",
    "        \"\"\"\n",
    "        현재 아티팩트 URI 반환\n",
    "\n",
    "        Returns:\n",
    "            str: 현재 아티팩트 URI\n",
    "        \"\"\"\n",
    "        return mlflow.get_artifact_uri()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "Make Dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [04:06<00:00, 127.02it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.5979 | Val Loss: 0.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:29:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 20%|██        | 1/5 [01:27<05:49, 87.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 0.3769 | Val Loss: 0.3431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:31:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 40%|████      | 2/5 [02:56<04:25, 88.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train Loss: 0.3458 | Val Loss: 0.3369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:32:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 60%|██████    | 3/5 [04:26<02:57, 88.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train Loss: 0.3336 | Val Loss: 0.3340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:34:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 80%|████████  | 4/5 [05:55<01:29, 89.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train Loss: 0.3255 | Val Loss: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:35:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 5/5 [07:25<00:00, 89.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run unequaled-dove-244 at: http://10.28.224.212:30627/#/experiments/352035656253646964/runs/60d71e24c60a48edab84d4ed6502ec90\n",
      "🧪 View experiment at: http://10.28.224.212:30627/#/experiments/352035656253646964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ml = MlflowManager(user_name=\"lagom\", experiment_name=\"tmp\")\n",
    "\n",
    "with ml.start_run(run_name=None):\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    print(\"device: \", device)\n",
    "\n",
    "    data_dir = \"/data/ephemeral/home/level2-recsys-movierecommendation-recsys-04-lv3/.data\"\n",
    "\n",
    "    train_loader, val_loader, (n_user, n_item) = FMdataloader(data_dir)\n",
    "\n",
    "    input_dims = [n_user, n_item]\n",
    "    embedding_dim = 10\n",
    "    lr = 0.001\n",
    "    num_epochs = 5\n",
    "\n",
    "    # Save MLflow log params\n",
    "    # ml.log_params({\"learning_rate\": lr})\n",
    "    # ml.log_params({\"embedding_dim\": embedding_dim})\n",
    "    # ml.log_params({\"num_epochs\": num_epochs})\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': lr,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'num_epochs': num_epochs\n",
    "    }\n",
    "    ml.log_params(params)\n",
    "\n",
    "    model = DeepFM(input_dims, embedding_dim, mlp_dims=[30, 20, 10]).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    min_val_loss = float('inf')\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y.float())\n",
    "                val_loss += loss.item()\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save MLflow log metric\n",
    "        ml.log_metric(\"time_to_train\", time.time() - start, step=epoch)\n",
    "        ml.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        ml.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "\n",
    "        # Save model\n",
    "        if min_val_loss > val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            Path(\"/data/ephemeral/home/level2-recsys-movierecommendation-recsys-04-lv3/.saved/deepFM\").mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(model, \"/data/ephemeral/home/level2-recsys-movierecommendation-recsys-04-lv3/.saved/deepFM/deepFM_base.pt\")\n",
    "\n",
    "            # Save MLflow log model\n",
    "            ml.log_model(model, \"DeepFM_model\", type='torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
