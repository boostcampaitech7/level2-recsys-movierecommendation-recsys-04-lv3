{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, input_dims, embedding_dim, mlp_dims, drop_rate=0.1):\n",
    "        super(DeepFM, self).__init__()\n",
    "        total_input_dim = int(sum(input_dims))\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros((1,)))\n",
    "        self.fc = nn.Embedding(total_input_dim, 1)\n",
    "        \n",
    "        self.embedding = nn.Embedding(total_input_dim, embedding_dim) \n",
    "        self.embedding_dim = len(input_dims) * embedding_dim\n",
    "\n",
    "        mlp_layers = []\n",
    "        for i, dim in enumerate(mlp_dims):\n",
    "            if i==0:\n",
    "                mlp_layers.append(nn.Linear(self.embedding_dim, dim))\n",
    "            else:\n",
    "                mlp_layers.append(nn.Linear(mlp_dims[i-1], dim))\n",
    "            mlp_layers.append(nn.ReLU(True))\n",
    "            mlp_layers.append(nn.Dropout(drop_rate))\n",
    "        mlp_layers.append(nn.Linear(mlp_dims[-1], 1))\n",
    "        self.mlp_layers = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def fm(self, x):\n",
    "        embed_x = self.embedding(x)\n",
    "        fm_y = self.bias + torch.sum(self.fc(x), dim=1)\n",
    "        square_of_sum = torch.sum(embed_x, dim=1) ** 2         \n",
    "        sum_of_square = torch.sum(embed_x ** 2, dim=1) \n",
    "        fm_y += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n",
    "        return fm_y\n",
    "    \n",
    "    def mlp(self, x):\n",
    "        embed_x = self.embedding(x) \n",
    "        inputs = embed_x.view(-1, self.embedding_dim)\n",
    "        mlp_y = self.mlp_layers(inputs)\n",
    "        return mlp_y\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed_x = self.embedding(x)\n",
    "        fm_y = self.fm(x).squeeze(1)\n",
    "        mlp_y = self.mlp(x).squeeze(1)\n",
    "        y = torch.sigmoid(fm_y + mlp_y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "def FMpreprecessing(data_dir):\n",
    "    train_ratings = pd.read_csv(f\"{data_dir}/train/train_ratings.csv\", sep=',')\n",
    "\n",
    "    train_ratings['rating'] = 1.0 # implicit feedback\n",
    "    train_ratings.drop(['time'],axis=1,inplace=True)\n",
    "\n",
    "    users = set(train_ratings.loc[:, 'user'])\n",
    "    items = set(train_ratings.loc[:, 'item'])\n",
    "\n",
    "    num_negative = 50\n",
    "    user_group_dfs = list(train_ratings.groupby('user')['item'])\n",
    "    first_row = True\n",
    "    user_neg_dfs = pd.DataFrame()\n",
    "\n",
    "    for u, u_items in tqdm(user_group_dfs):\n",
    "        u_items = set(u_items)\n",
    "        i_user_neg_item = np.random.choice(list(items - u_items), num_negative, replace=False)\n",
    "        \n",
    "        i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'rating': [0]*num_negative})\n",
    "        if first_row == True:\n",
    "            user_neg_dfs = i_user_neg_df\n",
    "            first_row = False\n",
    "        else:\n",
    "            user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n",
    "\n",
    "    train_ratings = pd.concat([train_ratings, user_neg_dfs], axis = 0, sort=False)\n",
    "\n",
    "    users = list(set(train_ratings.loc[:,'user']))\n",
    "    users.sort()\n",
    "    items =  list(set((train_ratings.loc[:, 'item'])))\n",
    "    items.sort()\n",
    "\n",
    "    if len(users)-1 != max(users):\n",
    "        users_dict = {users[i]: i for i in range(len(users))}\n",
    "        train_ratings['user']  = train_ratings['user'].map(lambda x : users_dict[x])\n",
    "        users = list(set(train_ratings.loc[:,'user']))\n",
    "        \n",
    "    if len(items)-1 != max(items):\n",
    "        items_dict = {items[i]: i for i in range(len(items))}\n",
    "        train_ratings['item']  = train_ratings['item'].map(lambda x : items_dict[x])\n",
    "        items =  list(set((train_ratings.loc[:, 'item'])))\n",
    "\n",
    "    data = train_ratings.sort_values(by=['user'])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    n_data = len(data)\n",
    "    n_user = len(users)\n",
    "    n_item = len(items)\n",
    "\n",
    "    user_col = torch.tensor(data.loc[:,'user'])\n",
    "    item_col = torch.tensor(data.loc[:,'item'])\n",
    "\n",
    "    offsets = [0, n_user, n_user+n_item]\n",
    "    for col, offset in zip([user_col, item_col], offsets):\n",
    "        col += offset\n",
    "\n",
    "    X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1)], dim=1)\n",
    "    y = torch.tensor(list(data.loc[:,'rating']))\n",
    "\n",
    "    return X, y, n_data, n_user, n_item\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, input_tensor, target_tensor):\n",
    "        self.input_tensor = input_tensor.long()\n",
    "        self.target_tensor = target_tensor.long()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_tensor[index], self.target_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_tensor.size(0)\n",
    "\n",
    "\n",
    "def FMdataloader(data_dir):\n",
    "    print(\"Make Dataloader\")\n",
    "    X, y, n_data, n_user, n_item = FMpreprecessing(data_dir)\n",
    "\n",
    "    dataset = FMDataset(X, y)\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    train_size = int(train_ratio * n_data)\n",
    "    test_size = n_data - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, (n_user, n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "\n",
    "class MlflowManager:\n",
    "    '''\n",
    "    MLflow ê´€ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤\n",
    "    \n",
    "    MLflow UI ì‹¤í–‰ ë°©ë²•:\n",
    "    mlflow ui -h 0.0.0.0 -p 30627\n",
    "\n",
    "    Attributes:\n",
    "        user_name: MLflow ì‚¬ìš©ì ì´ë¦„ (str)\n",
    "        tracking_uri: MLflow ì¶”ì  URI (str)\n",
    "        experiment_name: MLflow ì‹¤í—˜ ì´ë¦„ (str)\n",
    "\n",
    "    Methods:\n",
    "        init: MLflow ì´ˆê¸° ì„¤ì •\n",
    "        start_run: MLflow ì‹¤í–‰ ì‹œì‘\n",
    "        log_params: íŒŒë¼ë¯¸í„° ë¡œê¹…\n",
    "        log_metric: ë©”íŠ¸ë¦­ ë¡œê¹…\n",
    "        log_artifact: ì•„í‹°íŒ©íŠ¸ ë¡œê¹…\n",
    "        log_model: ëª¨ë¸ ë¡œê¹…\n",
    "        end_run: MLflow ì‹¤í–‰ ì¢…ë£Œ\n",
    "        autolog: MLflow ìë™ ë¡œê¹… ì„¤ì •\n",
    "        get_tracking_uri: í˜„ì¬ ì„¤ì •ëœ tracking URI ë°˜í™˜\n",
    "        get_artifact_uri: í˜„ì¬ ì•„í‹°íŒ©íŠ¸ URI ë°˜í™˜\n",
    "    '''\n",
    "    def __init__(self, user_name=\"root\", tracking_uri=\"http://10.28.224.212\", port=30627, experiment_name=\"tmp\"):\n",
    "        \"\"\"\n",
    "        MlflowManager í´ë˜ìŠ¤ ì´ˆê¸°í™”\n",
    "\n",
    "        Args:\n",
    "            user_name (str): MLflow ì‚¬ìš©ì ì´ë¦„\n",
    "            tracking_uri (str): MLflow ì¶”ì  ì„œë²„ URI\n",
    "            port (int): MLflow ì¶”ì  ì„œë²„ í¬íŠ¸\n",
    "            experiment_name (str): MLflow ì‹¤í—˜ ì´ë¦„\n",
    "        \"\"\"\n",
    "        self.user_name = user_name\n",
    "        os.environ[\"LOGNAME\"] = self.user_name\n",
    "        self.tracking_uri = f\"{tracking_uri}:{port}\"\n",
    "        self.experiment_name = experiment_name\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"MLflow ì´ˆê¸° ì„¤ì •\"\"\"\n",
    "        mlflow.set_tracking_uri(self.tracking_uri)\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def start_run(self, run_name=None):\n",
    "        \"\"\"\n",
    "        MLflow ì‹¤í–‰ ì‹œì‘\n",
    "\n",
    "        Args:\n",
    "            run_name (str, optional): ì‹¤í–‰ ì´ë¦„\n",
    "\n",
    "        Returns:\n",
    "            mlflow.ActiveRun: í™œì„±í™”ëœ MLflow ì‹¤í–‰ ê°ì²´\n",
    "        \"\"\"\n",
    "        return mlflow.start_run(run_name=run_name)\n",
    "\n",
    "    def log_params(self, params):\n",
    "        \"\"\"\n",
    "        íŒŒë¼ë¯¸í„° ë¡œê¹…\n",
    "\n",
    "        Args:\n",
    "            params (dict): ë¡œê¹…í•  íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬\n",
    "        \"\"\"\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "    def log_metric(self, key, value, step):\n",
    "        \"\"\"\n",
    "        ë©”íŠ¸ë¦­ ë¡œê¹…\n",
    "\n",
    "        Args:\n",
    "            key (str): ë©”íŠ¸ë¦­ ì´ë¦„\n",
    "            value (float): ë©”íŠ¸ë¦­ ê°’\n",
    "            step (int): í˜„ì¬ ìŠ¤í…\n",
    "        \"\"\"\n",
    "        mlflow.log_metric(key, value, step)\n",
    "\n",
    "    def log_artifact(self, local_path):\n",
    "        \"\"\"\n",
    "        ì•„í‹°íŒ©íŠ¸ ë¡œê¹…\n",
    "\n",
    "        Args:\n",
    "            local_path (str): ë¡œê¹…í•  ì•„í‹°íŒ©íŠ¸ì˜ ë¡œì»¬ ê²½ë¡œ\n",
    "        \"\"\"\n",
    "        mlflow.log_artifact(local_path)\n",
    "\n",
    "    def log_model(self, model, artifact_path, type='torch'):\n",
    "        \"\"\"\n",
    "        ëª¨ë¸ ë¡œê¹…\n",
    "\n",
    "        Args:\n",
    "            model: ë¡œê¹…í•  ëª¨ë¸ ê°ì²´\n",
    "            artifact_path (str): ì•„í‹°íŒ©íŠ¸ ì €ì¥ ê²½ë¡œ\n",
    "            type (str): ëª¨ë¸ íƒ€ì… ('torch' ë˜ëŠ” 'lgb')\n",
    "\n",
    "        Raises:\n",
    "            Exception: ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…ì¼ ê²½ìš° ë°œìƒ\n",
    "        \"\"\"\n",
    "        if type == 'torch':\n",
    "            mlflow.pytorch.log_model(model, artifact_path)\n",
    "        elif type == 'lgb':\n",
    "            mlflow.lightgbm.log_model(model, artifact_path)\n",
    "        else:\n",
    "            raise Exception(f\"Check type: {type}\")\n",
    "        return None\n",
    "\n",
    "    def end_run(self):\n",
    "        \"\"\"MLflow ì‹¤í–‰ ì¢…ë£Œ\"\"\"\n",
    "        mlflow.end_run()\n",
    "\n",
    "    def get_tracking_uri(self):\n",
    "        \"\"\"\n",
    "        í˜„ì¬ ì„¤ì •ëœ tracking URI ë°˜í™˜\n",
    "\n",
    "        Returns:\n",
    "            str: í˜„ì¬ ì„¤ì •ëœ tracking URI\n",
    "        \"\"\"\n",
    "        return mlflow.get_tracking_uri()\n",
    "\n",
    "    def get_artifact_uri(self):\n",
    "        \"\"\"\n",
    "        í˜„ì¬ ì•„í‹°íŒ©íŠ¸ URI ë°˜í™˜\n",
    "\n",
    "        Returns:\n",
    "            str: í˜„ì¬ ì•„í‹°íŒ©íŠ¸ URI\n",
    "        \"\"\"\n",
    "        return mlflow.get_artifact_uri()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "Make Dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31360/31360 [04:06<00:00, 127.02it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.5979 | Val Loss: 0.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:29:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 20%|â–ˆâ–ˆ        | 1/5 [01:27<05:49, 87.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 0.3769 | Val Loss: 0.3431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:31:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [02:56<04:25, 88.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train Loss: 0.3458 | Val Loss: 0.3369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:32:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [04:26<02:57, 88.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train Loss: 0.3336 | Val Loss: 0.3340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:34:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [05:55<01:29, 89.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train Loss: 0.3255 | Val Loss: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/19 08:35:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:25<00:00, 89.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run unequaled-dove-244 at: http://10.28.224.212:30627/#/experiments/352035656253646964/runs/60d71e24c60a48edab84d4ed6502ec90\n",
      "ğŸ§ª View experiment at: http://10.28.224.212:30627/#/experiments/352035656253646964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ml = MlflowManager(user_name=\"lagom\", experiment_name=\"tmp\")\n",
    "\n",
    "with ml.start_run(run_name=None):\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    print(\"device: \", device)\n",
    "\n",
    "    data_dir = \"/data/ephemeral/home/level2-recsys-movierecommendation-recsys-04-lv3/.data\"\n",
    "\n",
    "    train_loader, val_loader, (n_user, n_item) = FMdataloader(data_dir)\n",
    "\n",
    "    input_dims = [n_user, n_item]\n",
    "    embedding_dim = 10\n",
    "    lr = 0.001\n",
    "    num_epochs = 5\n",
    "\n",
    "    # Save MLflow log params\n",
    "    # ml.log_params({\"learning_rate\": lr})\n",
    "    # ml.log_params({\"embedding_dim\": embedding_dim})\n",
    "    # ml.log_params({\"num_epochs\": num_epochs})\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': lr,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'num_epochs': num_epochs\n",
    "    }\n",
    "    ml.log_params(params)\n",
    "\n",
    "    model = DeepFM(input_dims, embedding_dim, mlp_dims=[30, 20, 10]).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    min_val_loss = float('inf')\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y.float())\n",
    "                val_loss += loss.item()\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save MLflow log metric\n",
    "        ml.log_metric(\"time_to_train\", time.time() - start, step=epoch)\n",
    "        ml.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        ml.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "\n",
    "        # Save model\n",
    "        if min_val_loss > val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            Path(\"/data/ephemeral/home/level2-recsys-movierecommendation-recsys-04-lv3/.saved/deepFM\").mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(model, \"/data/ephemeral/home/level2-recsys-movierecommendation-recsys-04-lv3/.saved/deepFM/deepFM_base.pt\")\n",
    "\n",
    "            # Save MLflow log model\n",
    "            ml.log_model(model, \"DeepFM_model\", type='torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
